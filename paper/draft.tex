% using aastex version 6.1
\documentclass{aastex61}

%% The default is a single spaced, 10 point font, single spaced article.
%% There are 5 other style options available via an optional argument. They
%% can be envoked like this:
%%
%% \documentclass[argument]{aastex61}
%% 
%% where the arguement options are:
%%
%%  twocolumn   : two text columns, 10 point font, single spaced article.
%%                This is the most compact and represent the final published
%%                derived PDF copy of the accepted manuscript from the publisher
%%  manuscript  : one text column, 12 point font, double spaced article.
%%  preprint    : one text column, 12 point font, single spaced article.  
%%  preprint2   : two text columns, 12 point font, single spaced article.
%%  modern      : a stylish, single text column, 12 point font, article with
%% 		  wider left and right margins. This uses the Daniel
%% 		  Foreman-Mackey and David Hogg design.
%%
%% Note that you can submit to the AAS Journals in any of these 6 styles.
%%
%% There are other optional arguments one can envoke to allow other stylistic
%% actions. The available options are:
%%
%%  astrosymb    : Loads Astrosymb font and define \astrocommands. 
%%  tighten      : Makes baselineskip slightly smaller, only works with 
%%                 the twocolumn substyle.
%%  times        : uses times font instead of the default
%%  linenumbers  : turn on lineno package.
%%  trackchanges : required to see the revision mark up and print its output
%%  longauthor   : Do not use the more compressed footnote style (default) for 
%%                 the author/collaboration/affiliations. Instead print all
%%                 affiliation information after each name. Creates a much
%%                 long author list but may be desirable for short author papers
%%
%% these can be used in any combination, e.g.
%%
%% \documentclass[twocolumn,linenumbers,trackchanges]{aastex61}

%% AASTeX v6.* now includes \hyperref support. While we have built in specific
%% defaults into the classfile you can manually override them with the
%% \hypersetup command. For example,
%%
%%\hypersetup{linkcolor=red,citecolor=green,filecolor=cyan,urlcolor=magenta}
%%
%% will change the color of the internal links to red, the links to the
%% bibliography to green, the file links to cyan, and the external links to
%% magenta. Additional information on \hyperref options can be found here:
%% https://www.tug.org/applications/hyperref/manual.html#x1-40003

%% If you want to create your own macros, you can do so
%% using \newcommand. Your macros should appear before
%% the \begin{document} command.
%%
\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}
\newcommand{\fermi}{\mbox{\textit{Fermi}}}

%% Reintroduced the \received and \accepted commands from AASTeX v5.2

%\received{July 1, 2016}
%\revised{September 27, 2016}
%\accepted{\today}

%% Command to document which AAS Journal the manuscript was submitted to.
%% Adds "Submitted to " the arguement.

%\submitjournal{ApJ}

%% Mark up commands to limit the number of authors on the front page.
%% Note that in AASTeX v6.1 a \collaboration call (see below) counts as
%% an author in this case.
%
%\AuthorCollaborationLimit=3
%
%% Will only show Schwarz, Muench and "the AAS Journals Data Scientist 
%% collaboration" on the front page of this example manuscript.
%%
%% Note that all of the author will be shown in the published article.
%% This feature is meant to be used prior to acceptance to make the
%% front end of a long author article more manageable. Please do not use
%% this functionality for manuscripts with less than 20 authors. Conversely,
%% please do use this when the number of authors exceeds 40.
%%
%% Use \allauthors at the manuscript end to show the full author list.
%% This command should only be used with \AuthorCollaborationLimit is used.

%% The following command can be used to set the latex table counters.  It
%% is needed in this document because it uses a mix of latex tabular and
%% AASTeX deluxetables.  In general it should not be needed.
%\setcounter{table}{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% The following section outlines numerous optional output that
%% can be displayed in the front matter or as running meta-data.
%%
%% If you wish, you may supply running head information, although
%% this information may be modified by the editorial offices.
\shorttitle{QPO draft}
\shortauthors{Ick, Hogg, and Huppenkothen}
%%
%% You can add a light gray and diagonal water-mark to the first page 
%% with this command:
\watermark{DRAFT}
%% where "text", e.g. DRAFT, is the text to appear.  If the text is 
%% long you can control the water-mark size with:
%  \setwatermarkfontsize{dimension}
%% where dimension is any recognized LaTeX dimension, e.g. pt, in, etc.
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% This is the end of the preamble.  Indicate the beginning of the
%% manuscript itself with \begin{document}.


\begin{document}


\title{Gaussian Process Modeling: A Bayesian Approach to Detecting Quasi-Periodic Oscillations in Solar Flare Data} \label{sec:title and authors}
\correspondingauthor{Is that me?}
\email{chris.ick@nyu.edu, david.hogg@nyu.edu, daniela.huppenkothen@nyu.edu}

\author{Christopher A. Ick}
\affil{New York University\\
726 Broadway, Ofc 912 \\
New York, NY 10003, USA}

\author{David W. Hogg}
\affil{New York University\\
726 Broadway, Ofc 1005 \\
New York, NY 10003, USA}

\author{Daniela Huppenkothen}
\affil{University of Washington\\
3910 15th Ave NE\\
Office B356B\\
Seattle, WA 98195, USA}

\begin{abstract} \label{sec:abstract} 
	Solar flare analysis for quasi-periodic oscillations (QPOs)  was formally done using Fourier power spectra analysis, limiting computational efficiency to $\mathcal{O}(n^2)$.
We demonstrate a more effective and efficient method of modeling solar flare data using Gaussian Processes, a continuous-domain model, which scales at $\mathcal{O}(n)$ in one-dimensional models, and provide demonstrations of these methods by applying it to both simulated and real astronomical datasets.
Using the package Celerite for Gaussian processes, we provide demonstrations of effectively modeling QPOs using a self-correllation function (a kernel function) to model and simulate solar flare phenomena, and then to remodel and capture the original characteristics of the simulated flare data, using standard optimization methods as well as Markov-chain Monte Carlo sampling.
After demonstrating the effectiveness of these fitting methods, we go on to apply these modeling/fitting methods to capture the characteristics of real solar flare data, and discuss the potential use of the methods for automated solar flare and QPO detection.
\end{abstract}

\keywords{keywords go here}

\section{Introduction} \label{sec:intro}
Solar flares are the most powerful events in the solar system, releasing energies in excess of $10^{32}$~erg in tens of minutes across the entire electromagnetic spectrum \citep[e.g.\ ][]{fletcher2011}. 
They are closely connected to the acceleration of particles into interplanetary space and thus with variations in the solar wind observed as space weather. 
Solar flares tend to occur in magnetically active regions, and are believed to be caused by a rapid release of energy stored as inductive magnetic fields in the solar corona. 

Despite decades of study at all wavelengths, the exact conditions under which solar flares occur, their energy release mechanisms, and their radiation processes are not well understood.
Magnetic reconnection is believed to be the primary driver of the energy release, but many open questions about the exact processes occurring remain. 
The hard X-rays are believed to be caused by bremsstrahlung of accelerated electrons as they precipitate in the solar chromosphere,  but both the details of the electron acceleration and precipitation are currently unknown.
The detection of quasi-periodic pulsations (QPPs)\footnote{\normalsize{The same phenomenon is usually called quasi-periodic oscillation (QPO) in the astronomy community, but we will adhere to the solar physics nomenclature for consistency}} -- roughly coherent oscillations in the light curve on timescales of seconds to minutes -- has opened up the possibility of coronal seismology during solar flares. 
There is particuarly strong interest in hard X-ray QPPs, because they are believed to carry information about both solar flare triggering and energy release mechanisms \citep[see e.g.][]{nakariakov2009}. 
Flares are bright features that can be observed down to fractions of a second, making it possible to resolve the wave transit time across magnetic plasma structures and thus study magnetohydrodynamic (MHD) waves in more detail than possible in any other way. 

Understanding these processes in detail is important not only for advancing our understanding of solar MHD processes and plasma physics, but also of interest in the context of stellar flares now observed in abundance with instruments like \textit{Kepler}. 
Understanding the creation mechanisms of QPPs in solar flares will provide us with key diagnostics for the physical conditions in stars \citep[e.g.][]{kowalski2010}.
The details of the MHD processes and reconnection physics in the sun are highly relevant to other phenomena observable with \fermi/GBM where magnetic reconnection likely plays a key role, for example bursts from magnetars, whose triggering mechanisms are currently unknown  \citep{turolla2015}. 
Magnetar bursts have been likened to solar flares in their statistical properties and morphology before \citep{prieskorn2012} and have also shown QPPs\citep{huppenkothen2014}, thus it is not inconceivable that, while magnetars are vastly different from the sun, similar processes might occur in terms of the underlying reconnection.

The existence of QPPs in solar flares has been known for decades, but they have only recently emerged as key diagnostics of the plasma conditions and flare triggering processes \citep[e.g.][ and references therein]{nakariakov2009}. 
A key driving factor is the ability to study active solar regions with a high spatial and spectral resolution in multiple wavelength ranges. 

Significant progress has also been made in explaining QPPs with physical models, which generally fall into two classes.
In the first, magnetic reconnection proceeds in a ``bursty'', somewhat regular fashion, modulating the number of accelerated electrons and thus the intensity of the observed radiation \citep{kliem2000,ofman2006,murray2009}. 
The second class of models directly links the observed oscillations to MHD oscillations or waves in some of the flare parameters, e.g.\ the rate of energy release, particle acceleration, and particle dynamics \citep{nakariakov2007,pascoe2007}. 
In this case, periodicities are prescribed by resonances that act as direct tracer of the magnetic processes in the flare emitting region.

It is likely that QPPs in different flares are generated by different mechanisms, and several mechanisms might occur in the same flare.
It has been possible to infer the likely physical mechanisms operating for a very small sample ($\sim 5$) of flares \citep{asai2001,melnikov2005,inglis2008}. In particular, the detection of multiple independent QPPs in a single flare is highly indicative of the underlying process because various physical models allow only for very specific resonances \citep{melnikov2005,inglis2009}. 
Multi-wavelength and spatially resolved data has also been crucial for understanding the properties of QPPs and their likely origin. 

Despite the successes in identifying the QPP mechanisms in few individual flares, no overall picture of QPP formation has emerged for the majority of flares. 
Observational data and current data analysis techniques do not permit an unambiguous choice between various models of QPPs in solar flares.
To date, none of the proposed models have been confidently excluded, nor have any been identified as the dominant QPP formation mechanism. 
This is partly due to the lack of high-quality multi-wavelength or spatially resolved data for many flares. 
However, there is a crucial dearth of large-scale sample studies of QPPs in solar flares, and it has therefore not been possible to relate QPP parameters to other physical properties of the flare. 
Studies of solar flare variability are often framed as QPP searches, leaving the information contained in variability patterns largely unexplored. (though some studies of the wavelength-dependence of variability exist, \citep{mcateer2007}).

The lack of large-scale studies of QPPs and variability is rooted in the technical challenge of QPP identification in the presence of complex structures in the hard X-ray light curve. 
Until recently, identification was a labour-intensive task, difficult to automate for large samples, and involved the manual de-trending of the light curve to remove the overall rising and falling trends of the \textit{flare envelope}, followed by a visual identification of the residuals to identify QPPs. 
As recently pointed out by \citep{inglis2015} this method is also error-prone, because it does not correctly account for inherent aperiodic variability (also called ``red noise'') present in the flare.
\citep{inglis2015} instead suggested a Fourier-based method taking account of this aperiodic variability based on methodology developed for Active Galactic Nuclei (AGN), while \citep{simoes2015} employed a similar approach using wavelets. 

Disentangling periodic and quasi-periodic signals from aperiodic variability has been a major problem for this field. 
The reason lies in the transient nature of these flares and bursts, for which Fourier methods are inherently not well suited, because the assumption that mean and variance of the data do not change over time breaks down in these data sets, as was shown for magnetar bursts in . 
This especially hurts QPP studies in solar flares because these signals are often observed at low frequencies where the biases introduced by the method are strongest. 

The current quandary is that two classes of methods exist, both of which make strong assumptions and neither of which is a good model of the data. On the one hand, detrending techniques assume the solar flare consists of two processes operating on independent time scales, a slowly varying flare envelope, and a faster, possibly periodic process. 

On the other hand, Fourier- and wavelet-based models assume a purely stochastic process switching on and off at the start and end of the flare, with a potential QPP on top of this process, but disregard the idea of an underlying envelope entirely. 
The former model is likely to grossly overestimate the number of QPPs found in solar flares because it often does not account for aperiodic variability. The latter has been shown to underestimate the number of QPPs at lower frequencies \citep{huppenkothen2013}. 
Both lead to systematic biases in the results that have not been adequately characterized.

The reliable detection of QPPs in solar flares is a difficult problem, but modern advances in computer science, particularly concerning a flexible class of models called Gaussian Processes \citep[GPs;][]{rasmussen2006}, point to a way forward. Instead of either directly modelling the lightcurve or some transformed version of it, GPs model the \textit{covariance} between data points with a parametric function (also called \textit{covariance function}). 

This approach has several clear advantages over alternative methods. (i) It represents the best of both worlds: it is possible to self-consistently include both deterministic components, e.g.\ a flare envelope, and stochastic components, such as red noise, \citep{aigrain2015}, in the same model. This eliminates common biases in the typical approach of removing the flare envelope by using a running boxcar. %The model represents the best of both worlds: it allows inclusion of the overall flaring shape of the solar flare, as well as the commonly observed red noise component. 
Both red noise and QPPs have direct formulations in terms of covariance functions, thus the model can be directly used as a basis to test for QPPs. 
(ii) The fully probabilistic formulation allows for straightforward model comparisons. It will be possible to test for the presence of various components (e.g. specific formulations of red noise or a flare envelope) directly, allowing for a much more precise model of the flare variability.
(iii) Even if no QPP is detected, the parameters of the covariance function serve as a proxy for relevant time scales in the system, allowing for direct interpretation of these time scales e.g.\ in the context of models for bursty reconnection. 



\section{Data} \label{sec:data}
Data for this project was acquired from the Gamma-ray Burst Monitor (GBM) onboard the Fermi Gamma-ray Space Telescope, as well as the GOES-15 sattelite's x-ray imager.
Solar flare data from GOES  was provided by Andrew Inglis.
The data is formatted in a .fits file, with thw first two columns corresponding to the flux of the 1-8\AA and 0.5-4\AA channels respectively.



\section{Methods} \label{sec:methods}
Once our data is cleanly organized into a time series containing time coordinates of our measurements, $x$, intensity measurements, $y$, and error $\delta_y$, in separate arrays, we can begin our modeling algorithm. We model the flare envelope using the flare model:

\begin{equation}
	\mu_{\theta}(t) = A \lambda exp{\left( \frac{-\tau_1}{t-t_s}-\frac{t-t_s}{\tau_2}\right)}
	\label{model}
\end{equation}

where $t$ is the time since trigger, $t_s$ is the trigger time, $A$ is the flare evelope amplitude, $\tau_1$ and $\tau_2$ are characteristics of the pulse rise and decay respectively, and 
$\lambda = exp(2\frac{\tau_1}{\tau_2})^{1/2}$ (CITATION)
The free parameters for our fit are $A$, $\tau_1$, and $\tau_2$, which we will refer to as $\theta$, a parameter vector.
We generate our initial guesses for this parameter vector using a simple function that takes the maximum of the flare as $A$, $\tau_1$ to be $\frac{1}{3}$ of the length of our flare, and $\tau_2$ to similarly be $\frac{2}{3}$ the length of our flare.
These initial guesses need only to be approximate, as we'll be optimizing these values after defining all free parameters of our model.

To model a QPO, we use a covariance function, or kernel function $k(\tau_{ij})$, where $\tau_{ij}$ is the matrix $\tau_{ij} = t_i-t_j$. To model a QPO using a kernel, we begin utilizing Celerite, a library for 1D Gaussian process regression. We can initialize our envelope model using the aptly-named abstract ``Model'' class.
Similarly, using Celerite's built-in ``terms'' class, we define a kernel representing stochastically-driven, dampened harmonic oscillator, defined by the differential equation:\footnote{I can include the whole solution set, which depends on the size of the quality factor $Q$, is that useful?}


\begin{equation}
	\left( \frac{d^2}{dt^2} + \frac{\omega_0}{Q} \frac{d}{dt} + \omega_0^2 \right) y(t) = \epsilon(t) 
	\label{sho}
\end{equation}

Where $\omega_0$ corresponds to the natural frequency of the undamped oscillator, $Q$ is the quality factor, and $\epsilon(t)$ is a stochastic driving force.
There is an additional scaling term $S_0$ in the PSD of this process that corresponds to the power at natural frequency, $\omega=\omega_0$.
Working under the assumption that all quasi-periodic oscillations are triggered by the same mechanism, we set our initial values of these parameters as those we captured from a real flare.

Finally, we similarly model a red noise process using another model in the ``terms'' class in Celerite defined by:

\begin{equation}
	k(\tau) = a * exp(-c\tau)
	\label{rednoise}
\end{equation}

Where $a$ and $c$ are similar terms for correlational strength and timescale, that are similarly free, and guessed based on known values from a real solar flare.
One convenience of our modeling protocol is that we can combine multiple kernel functions into a composite kernel, $k_\alpha$, which will autmatically concatenate the individual parameter vectors for each kernel into one large parameter vector, which we'll denote as $\alpha$.

Since we are using a Bayesian probability measurement as our fitting function, we can encode our prior knowledge of our parameters into our models, as prior distributions. 
For the sake of convenience and simplicity, we applied tophat priors for each of these parameters within reasonable known values of these parameters. 
\footnote{We may want to think about our priors a bit more before I write out a table for them\ldots}	


From here, we have all neccessary information to initialize our models: the envelope model and the kernel functions are initialized with their parameters, the initial guesses for each parameter, and the prior distribution for each parameter.
From here, we can initialize a GP-class (Gaussian Process) object, utilizing the model as the mean function for the process, and the kernel function as a constructor for the kernel matrix.
Once initialized, we have access to several of the GP computations encoded in the Celerite solver, such as computing the kernel matrix and factorizing.

With these computations ready, we feed the time coordinates ($x$) as well as intensity error ($\delta_y$) into the GP.compute() function to compute the kernel matrix.
With the kernel matrix computed, we can begin the optimization process. For a fit, we want to maximize the likelihood of our fit over parameterspace defined by $\theta$ and $\alpha$. 
For a Bayesian model, we can write out the computation of the likelihood as a result of Bayes theorem \footnote{Do I need to know how to derive this?}. It's more useful to write out the log-form:

\begin{equation}
	\ln \mathcal{L}(\theta, \alpha) = \ln p(y|x, \theta, \alpha) = -\frac{1}{2}r_\theta^T K_\alpha^{-1}r_\theta - \ln det(K_\alpha)^{\frac{1}{2}} - \frac{N}{2}\ln(2 \pi)
	\label{loglike}
\end{equation}

Where the vector $r_\theta \equiv y-\mu_\theta (x)$. With this function defined, we can define a function that computes the negative log-likelihood ($-\mathcal{L}$) as a function of the joint parameter vector ($\theta, \alpha$).
With this, we can use any optimization scheme to find the optimal values for the parameter vectors; in our case, we called the minimize function from scipy's optimization submodule, utilizing Limited-memory BFGS optimization.

This is generally sufficient to compute the optimal parameters of the solar flare envelope, $\theta$, but for the QPO parameters, $\alpha$, we can better understand the parameter-space, and to maximize the probability of our fit by using Markov chain Monte Carlo sampling (MCMC).
Using the emcee package, we initialize a set of walkers to explore the parameter-space of the model, distributed about the optimal parameters previously computed. Defining a log-probability method as the sum of our likelihood computation as well as our prior at the parameterspace $\theta$ acts as our probability distribution for our walkers.


\section{Discussion} \label{sec:discussion}
Let's talk about what happened.


\bibliography{solarflares}



%\begin{thebibliography}{}
%	\bibitem[Something(2017)]{numbers}Something 2017
%\end{thebibliography}

\end{document}

